{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#!pip install numpy==1.19.5\n",
    "#!pip install tensorflow==2.2.0\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "#from tensorflow import keras\n",
    "### hack tf-keras to appear as top level keras\n",
    "#import sys\n",
    "#sys.modules['keras'] = keras\n",
    "### end of hack\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Reshape\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the key parameters\n",
    "batch_size = 20\n",
    "\n",
    "IMG_SIZE = 80 # default 236\n",
    "# Parameters of the input images (handwritten digits)\n",
    "# 236 x 236\n",
    "original_dim = IMG_SIZE*IMG_SIZE\n",
    "\n",
    "# Latent space is of dimension 2.  This means that we are reducing the dimension from 784 to 2\n",
    "latent_dim = 2\n",
    "second_dim = 256\n",
    "intermediate_dim = 640\n",
    "epochs = 200\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2  # pip3 install opencv-python\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "path = \"images\"\n",
    "images = []\n",
    "y =[]\n",
    "for img in os.listdir(path):\n",
    "    try:\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        if j == 199:\n",
    "            plt.imshow(img_array, cmap=\"gray\")\n",
    "            plt.show()\n",
    "        new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "        if j != 134 and j!=155 and j!=363 and j!=366:\n",
    "            images.append(new_array)\n",
    "            y.append(j)\n",
    "        j+=1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    # plt.imshow(img_array, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # i +=1\n",
    "    # if i == 0:\n",
    "    #     break\n",
    "print(len(images))    \n",
    "\n",
    "# new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "# plt.imshow(new_array, cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# j = 0\n",
    "# for image in new_array:\n",
    "#     images.append(image)\n",
    "#     y.append(j)\n",
    "#     j+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "\n",
    "x_train = X \n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "y_train = y\n",
    "\n",
    "\n",
    "# x_test = np.array(images[301:]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "# x_test = x_test.astype('float32') / 255.\n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "# print(len(x_test))\n",
    "# y_test = list(range(128))\n",
    "\n",
    "x_test = x_train\n",
    "y_test = y\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# print(y_train)\n",
    "\n",
    "#x_train = x_train.astype('float32') / 255.\n",
    "#x_test = x_test.astype('float32') / 255.\n",
    "#x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "#x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args: tuple):\n",
    "    # we grab the variables from the tuple\n",
    "    z_mean, z_log_var = args\n",
    "    print(z_mean)\n",
    "    print(z_log_var)\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon  # h(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input to our encoder\n",
    "x = Input(shape=(original_dim,), name=\"input\")\n",
    "# intermediate layer\n",
    "h = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x)\n",
    "\n",
    "h = Dense(second_dim, activation='relu', name=\"encoding2\")(h)\n",
    "\n",
    "# defining the mean of the latent space\n",
    "z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
    "# defining the log variance of the latent space\n",
    "z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "# defining the encoder as a keras model\n",
    "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "# print out summary of what we just did\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the decoder\n",
    "input_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "# taking the latent space to intermediate dimension\n",
    "decoder_h = Dense(second_dim, activation='relu', name=\"decoder_h2\")(input_decoder)\n",
    "decoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(decoder_h)\n",
    "# decoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(input_decoder)\n",
    "\n",
    "# getting the mean from the original dimension\n",
    "x_decoded = Dense(original_dim, activation='sigmoid', name=\"flat_decoded\")(decoder_h)\n",
    "# defining the decoder as a keras model\n",
    "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the output. Recall, that we need to grab the 3rd element our sampling z\n",
    "output_combined = decoder(encoder(x)[2])\n",
    "# link the input and the overall output\n",
    "vae = Model(x, output_combined)\n",
    "# print out what the overall model looks like\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE Loss Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras import metrics\n",
    "\n",
    "def vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor):\n",
    "  # Aca se computa la cross entropy entre los \"labels\" x que son los valores 0/1 de los pixeles, y lo que saliÃ³ al final del Decoder.\n",
    "  xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean) # x-^X\n",
    "  kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "  vae_loss = K.mean(xent_loss + kl_loss)\n",
    "  return vae_loss\n",
    "\n",
    "vae.compile( loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)[0]\n",
    "i = 0\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='viridis')\n",
    "# for xi in x_test_encoded:\n",
    "#     plt.text(xi[0], xi[1], i)\n",
    "#     if xi[1]> -12:\n",
    "#         print(xi)\n",
    "#     i += 1\n",
    "# plt.text(x_test_encoded[:,0], x_test_encoded[:,1], y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vector = np.array([[-4,-2.5]])\n",
    "decoded_example = decoder.predict(sample_vector)\n",
    "decoded_example_reshaped = decoded_example.reshape(80, 80)\n",
    "plt.imshow(decoded_example_reshaped, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5  # figure with 15x15 digits\n",
    "digit_size = 80\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "print(grid_y)\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_sample)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
