{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import Autoencoder\n",
    "from parser import data_converter, print_letter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.array(data_converter(\"resources\"))\n",
    "# for char in alphabet:\n",
    "#     print_letter(char)\n",
    "# print(len(alphabet))\n",
    "flattened_input = np.array(list(map(lambda char: np.array(char).flatten(), alphabet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "errors =[]\n",
    "\n",
    "def callback_fun(e, error, w, o):\n",
    "    epochs.append(e)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activation_function = (lambda x: 1/(1+np.exp(-2*x)))\n",
    "activation_derivative = (lambda x: 2*(1/(1+np.exp(-2*x)))*(1-(1/(1+np.exp(-2*x)))) )\n",
    "ae = Autoencoder(35, [17, 8], latent_dim=2, activation_function=activation_function,activation_function_derivative=activation_derivative, update_learn_rate=None, learning_rate=0.01)\n",
    "\n",
    "\n",
    "output, err_min = ae.train(flattened_input, expected_output=flattened_input, epoch_limit=1500, callback=callback_fun)\n",
    "\n",
    "print(err_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "print_letter(alphabet[i])\n",
    "reconstruct, reconstruction_error = ae.reconstruct(flattened_input[i])\n",
    "\n",
    "print_letter(reconstruct.reshape(alphabet[i].shape))\n",
    "print(reconstruction_error)\n",
    "\n",
    "latent_output = ae.encode(flattened_input[i])\n",
    "print(latent_output)\n",
    "print_letter(ae.decode(latent_output).reshape(alphabet[i].shape))\n",
    "\n",
    "ae.graph_latent_space(flattened_input)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
