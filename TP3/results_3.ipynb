{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.file_utils as fu\n",
    "import perceptrons.multilayer_perceptron as mlp\n",
    "import numpy as np\n",
    "import graphing as g\n",
    "from tabulate import tabulate\n",
    "import ex_3.main as main\n",
    "import metrics as m\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"ex_3/resources/config.json\"\n",
    "config_file = fu.parse_config(path_to_config)\n",
    "\n",
    "path_to_data = config_file[\"path_to_data\"]\n",
    "epoch_limit = int(config_file[\"epoch_limit\"])\n",
    "execution_count = int(config_file[\"execution_count\"])\n",
    "momentum = bool(config_file[\"momentum\"])\n",
    "cross_validation_k = int(config_file[\"cross_validation\"])\n",
    "hidden_layers = config_file[\"hidden_layers\"]\n",
    "learn_rate = float(config_file[\"learn_rate\"])\n",
    "adaptive_learn_rate = bool(config_file[\"adaptive_learn_rate\"])\n",
    "subproblem = int(config_file[\"subproblem\"])\n",
    "activation_function = (lambda x: 1/(1+np.exp(-2*x)))\n",
    "activation_derivative = (lambda x: 2*(1/(1+np.exp(-2*x)))*(1-(1/(1+np.exp(-2*x)))) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subproblem == 1:\n",
    "    training_set = config_file[\"training_set\"]\n",
    "    expected_output = config_file[\"expected_output\"]\n",
    "\n",
    "    error_vs_iteration_path = \"ex_3/resources\"\n",
    "    open(error_vs_iteration_path+ \"/error_vs_iteration.txt\", \"w\").close()\n",
    "\n",
    "    p = mlp.MultiLayerPerceptron(learn_rate, hidden_layers, input_dim=len(training_set[0]), output_dim=len(expected_output[0]), update_frequency=0,\n",
    "    activation_function=activation_function, activation_function_derivative=activation_derivative, update_learn_rate=None, scale_output=False, momentum=momentum)\n",
    "\n",
    "    w, err = p.train(training_set, expected_output, epoch_limit, callback=(lambda i, error, weights, output: fu.write_error_vs_iteration(error_vs_iteration_path, error, i)))\n",
    "    g.error_vs_iteration(error_vs_iteration_path, True)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(len(training_set)):\n",
    "        print(\"Input: \"+str(training_set[i])+\" Expected output: \" + str(expected_output[i]) + \" Output: \" + str(p.forward_propagation(training_set[i])))\n",
    "        data.append([training_set[i], expected_output[i], p.forward_propagation(training_set[i])])\n",
    "\n",
    "    column_names =[\"Input\", \"Expected output\", \"Prediction\"]\n",
    "    print(tabulate(data, headers=column_names, tablefmt=\"fancy_grid\", showindex=\"always\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(output_val):\n",
    "    if output_val[0] > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def callback_fun(e, error, weights, output,input_set, output_set, test_input, test_output, i, perceptron):\n",
    "    results = [classify(perceptron.forward_propagation(item)) for item in input_set]\n",
    "    test_results = [classify(perceptron.forward_propagation(item)) for item in test_input]\n",
    "    test_err = perceptron.test_network(test_input, test_output)\n",
    "    cm_results = m.ConfusionMatrix(results, [item[0] for item in output_set], 0)\n",
    "    cm_test = m.ConfusionMatrix(test_results, [item[0] for item in test_output], 0)\n",
    "    if i is not None:\n",
    "        f = open(path_to_data+\"/generalization_error_{}.txt\".format(i), \"a\")\n",
    "    else:\n",
    "        f = open(path_to_data+\"/generalization_error.txt\", \"a\")\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(e, error, test_err[0], m.accuracy(cm_results), m.accuracy(cm_test), \n",
    "    m.precision(cm_results), m.precision(cm_test), m.recall(cm_results), m.recall(cm_test), m.f1_score(cm_results), m.f1_score(cm_test)))\n",
    "    f.close()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subproblem == 2:\n",
    "    path_to_data = \"ex_3/resources/training\"\n",
    "    training_set, expected_set = main.parse_ej2(path_to_data)\n",
    "    input_groups, expected_groups = m.cross_validation(training_set,  cross_validation_k, expected_set)\n",
    "    p = mlp.MultiLayerPerceptron(learn_rate, hidden_layers, len(training_set[0]), len(expected_set[0]), update_frequency=0,\n",
    "    activation_function=activation_function, activation_function_derivative=activation_derivative, update_learn_rate=None, scale_output=False, momentum=momentum)\n",
    "\n",
    "    for i, test_group in enumerate(input_groups):\n",
    "        open(path_to_data+\"/generalization_error_{}.txt\".format(i), \"w\").close()\n",
    "        errors =[]\n",
    "        t = input_groups[:i] + input_groups[i+1:]\n",
    "        input_set = [item for sublist in t for item in sublist]\n",
    "        e = expected_groups[:i] + expected_groups[i+1:]\n",
    "        output_set = [item for sublist in e for item in sublist]\n",
    "        w, err = p.train(input_set, output_set, epoch_limit, \n",
    "        callback=(lambda e, error, weights, output: callback_fun(e, error, weights, output,input_set, output_set, input_groups[i], expected_groups[i], i, p)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subproblem == 2:\n",
    "    j=1\n",
    "    for i in range(len(input_groups)):\n",
    "        print(expected_groups[i])\n",
    "        f = open(path_to_data+\"/generalization_error_{}.txt\".format(i), \"r\")\n",
    "        lines = f.readlines()\n",
    "        epochs = []\n",
    "        errors = []\n",
    "        test_errors = []\n",
    "        train_accs =[]\n",
    "        test_accs = []\n",
    "        train_precs = []\n",
    "        test_precs = []\n",
    "        train_recs = []\n",
    "        test_recs = []\n",
    "        train_f1s = []\n",
    "        test_f1s = []\n",
    "        for line in lines:\n",
    "            e, error, test_err, train_acc, test_acc, train_prec, test_prec, train_rec, test_rec, train_f1, test_f1  = line.split(\",\")\n",
    "            epochs.append(int(e))\n",
    "            errors.append(float(error))\n",
    "            test_errors.append(float(test_err))\n",
    "            train_accs.append(float(train_acc))\n",
    "            test_accs.append(float(test_acc))\n",
    "            train_precs.append(float(train_prec))\n",
    "            test_precs.append(float(test_prec))\n",
    "            train_recs.append(float(train_rec))\n",
    "            test_recs.append(float(test_rec))\n",
    "            train_f1s.append(float(train_f1))\n",
    "            test_f1s.append(float(test_f1))\n",
    "        f.close()\n",
    "        plt.figure(j)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.plot(epochs, errors, label=\"Training\")\n",
    "        plt.plot(epochs, test_errors, label=\"Test\")\n",
    "        plt.legend()\n",
    "        plt.figure(j+1)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.plot(epochs, train_accs, label=\"Training\")\n",
    "        plt.plot(epochs, test_accs, label=\"Test\")\n",
    "        plt.legend()\n",
    "        plt.figure(j+2)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.plot(epochs, train_precs, label=\"Training\")\n",
    "        plt.plot(epochs, test_precs, label=\"Test\")\n",
    "        plt.legend()\n",
    "        plt.figure(j+3)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Recall\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.plot(epochs, train_recs, label=\"Training\")\n",
    "        plt.plot(epochs, test_recs, label=\"Test\")\n",
    "        plt.legend()\n",
    "        plt.figure(j+4)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"F1 score\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.plot(epochs, train_f1s, label=\"Training\")\n",
    "        plt.plot(epochs, test_f1s, label=\"Test\")\n",
    "        plt.legend()\n",
    "\n",
    "        j+=5"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
